import pandas as pd
import joblib
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm 
import numpy as np
from underthesea import word_tokenize

# ========== C√†i ƒë·∫∑t ==========
input_file = "data/Products_ThoiTrangNam_clean.csv"
output_pkl = "models/content_based_model.pkl"

# ========== H√†m ti·ªÅn x·ª≠ l√Ω ==========
def preprocess_text(text):
    text = str(text).lower()
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'[^\w\s]', ' ', text)
    text = re.sub(r'\d+', '', text)
    return text

# ========== ƒê·ªçc & l·ªçc d·ªØ li·ªáu ==========
print("üì¶ ƒêang load d·ªØ li·ªáu...")
df = pd.read_csv(input_file)

# X·ª≠ l√Ω m√¥ t·∫£
df["combined_text"] = (df["product_name"].fillna("") + " " + df["clean_description"].fillna("")).apply(preprocess_text)

# word_tokenize
df["combined_text_wt"]=df["combined_text"].apply(lambda x: word_tokenize(x, format="text"))

# ƒê·ªçc stopwords t·ª´ file
STOP_WORD_FILE = 'data/vietnamese-stopwords.txt'
with open(STOP_WORD_FILE, 'r', encoding='utf-8') as file:
    stop_words = file.read()

stop_words = stop_words.split('\n')

# ========== X√¢y d·ª±ng m√¥ h√¨nh TF-IDF ==========
print("üîç ƒêang vector h√≥a TF-IDF...")
vectorizer = TfidfVectorizer(analyzer='word', stop_words=stop_words)
tfidf_matrix = vectorizer.fit_transform(df["combined_text_wt"])

# ========== T√≠nh to√°n cosine similarity ==========
item_ids = df['product_id'].tolist()
top_k = 20
top_k_dict = {}

print("üîÑ ƒêang t√≠nh cosine similarity t·ª´ng h√†ng")

# L·∫∑p qua t·ª´ng h√†ng
for idx in tqdm(range(tfidf_matrix.shape[0])):
    # L·∫•y vector tf-idf c·ªßa s·∫£n ph·∫©m hi·ªán t·∫°i
    item_vector = tfidf_matrix[idx]

    # T√≠nh cosine similarity v·ªõi to√†n b·ªô tf-idf matrix
    similarity_row = cosine_similarity(item_vector, tfidf_matrix).flatten()

    # Lo·∫°i b·ªè ch√≠nh n√≥
    similarity_row[idx] = -1

    # L·∫•y top-k
    top_indices = np.argsort(similarity_row)[-top_k:][::-1]
    top_items = [(item_ids[i], float(similarity_row[i])) for i in top_indices]

    top_k_dict[item_ids[idx]] = top_items

# ========== L∆∞u m√¥ h√¨nh ==========
print("üíæ ƒêang l∆∞u m√¥ h√¨nh .pkl ...")
model = {
    "tfidf_vectorizer": vectorizer,
    "tfidf_matrix": tfidf_matrix,
    "cosine_similarity": top_k_dict
}

joblib.dump(model, output_pkl)
print(f"üéâ M√¥ h√¨nh ƒë√£ l∆∞u v√†o {output_pkl}")